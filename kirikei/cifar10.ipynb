{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7c46f7",
   "metadata": {},
   "source": [
    "# CIFAR10\n",
    "* MLP-Mixer， Resnet， MLP, CNN-MLP, VGG-16で比較（予定）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09bd4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "\n",
    "import models, utils\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a16a58",
   "metadata": {},
   "source": [
    "* https://github.com/sayakpaul/MLP-Mixer-CIFAR10/blob/main/MLP_Mixer_Training.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786b2f0b",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d5ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34195c0d",
   "metadata": {},
   "source": [
    "### MLP-Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "38bbd64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    num_blocks = 10,\n",
    "    patch_size=4, \n",
    "    hidden_dim=128, \n",
    "    tokens_mlp_dim=64, \n",
    "    channels_mlp_dim=128,\n",
    "    mlp_block_params=dict(\n",
    "        activation='gelu',\n",
    "        dropout_rate=0.5,\n",
    "        dense_params=dict(\n",
    "            kernel_initializer='he_normal',\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "724fa7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer_model = models.mlp_mixer((32, 32, 3), num_classes=10, **parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1e10371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer_model.compile(Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "55e3b0e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 2.0289 - accuracy: 0.2257 - val_loss: 1.8566 - val_accuracy: 0.2962\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.7540 - accuracy: 0.3364 - val_loss: 1.6688 - val_accuracy: 0.3800\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.5467 - accuracy: 0.4268 - val_loss: 1.4558 - val_accuracy: 0.4750\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 1.4406 - accuracy: 0.4723 - val_loss: 1.3607 - val_accuracy: 0.4984\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.3796 - accuracy: 0.4970 - val_loss: 1.3127 - val_accuracy: 0.5220\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.3217 - accuracy: 0.5203 - val_loss: 1.2847 - val_accuracy: 0.5412\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.2757 - accuracy: 0.5382 - val_loss: 1.2300 - val_accuracy: 0.5580\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.2365 - accuracy: 0.5510 - val_loss: 1.1956 - val_accuracy: 0.5774\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.2026 - accuracy: 0.5645 - val_loss: 1.2003 - val_accuracy: 0.5798\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1742 - accuracy: 0.5778 - val_loss: 1.1765 - val_accuracy: 0.5864\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 1.1521 - accuracy: 0.5866 - val_loss: 1.1296 - val_accuracy: 0.5990\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1326 - accuracy: 0.5933 - val_loss: 1.1076 - val_accuracy: 0.6086\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1087 - accuracy: 0.6028 - val_loss: 1.0904 - val_accuracy: 0.6114\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 1.0868 - accuracy: 0.6106 - val_loss: 1.0942 - val_accuracy: 0.6130\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.0720 - accuracy: 0.6178 - val_loss: 1.1199 - val_accuracy: 0.6060\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 8s 95ms/step - loss: 1.0580 - accuracy: 0.6219 - val_loss: 1.0810 - val_accuracy: 0.6180\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 1.0317 - accuracy: 0.6325 - val_loss: 1.0565 - val_accuracy: 0.6284\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 1.0197 - accuracy: 0.6357 - val_loss: 1.0402 - val_accuracy: 0.6372\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.0040 - accuracy: 0.6437 - val_loss: 1.0319 - val_accuracy: 0.6420\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.9859 - accuracy: 0.6501 - val_loss: 1.0607 - val_accuracy: 0.6358\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.9814 - accuracy: 0.6506 - val_loss: 1.0170 - val_accuracy: 0.6458\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 8s 97ms/step - loss: 0.9687 - accuracy: 0.6538 - val_loss: 1.0299 - val_accuracy: 0.6420\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.9522 - accuracy: 0.6610 - val_loss: 1.0779 - val_accuracy: 0.6382\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.9408 - accuracy: 0.6664 - val_loss: 0.9994 - val_accuracy: 0.6618\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.9282 - accuracy: 0.6695 - val_loss: 1.0168 - val_accuracy: 0.6632\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.9197 - accuracy: 0.6743 - val_loss: 1.0686 - val_accuracy: 0.6472\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 8s 97ms/step - loss: 0.9078 - accuracy: 0.6784 - val_loss: 1.0067 - val_accuracy: 0.6618\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.9042 - accuracy: 0.6776 - val_loss: 0.9679 - val_accuracy: 0.6714\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 8s 97ms/step - loss: 0.8919 - accuracy: 0.6853 - val_loss: 1.0265 - val_accuracy: 0.6570\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.8806 - accuracy: 0.6846 - val_loss: 0.9584 - val_accuracy: 0.6748\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.8778 - accuracy: 0.6898 - val_loss: 1.0371 - val_accuracy: 0.6510\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.8681 - accuracy: 0.6920 - val_loss: 0.9850 - val_accuracy: 0.6696\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.8630 - accuracy: 0.6936 - val_loss: 0.9889 - val_accuracy: 0.6752\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.8449 - accuracy: 0.7025 - val_loss: 0.9628 - val_accuracy: 0.6752\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.8477 - accuracy: 0.6966 - val_loss: 0.9806 - val_accuracy: 0.6802\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 9s 100ms/step - loss: 0.8379 - accuracy: 0.7035 - val_loss: 0.9742 - val_accuracy: 0.6824\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 8s 97ms/step - loss: 0.8266 - accuracy: 0.7076 - val_loss: 0.9846 - val_accuracy: 0.6716\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.8261 - accuracy: 0.7069 - val_loss: 0.9356 - val_accuracy: 0.6876\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.8118 - accuracy: 0.7109 - val_loss: 0.9625 - val_accuracy: 0.6790\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.8131 - accuracy: 0.7100 - val_loss: 0.9374 - val_accuracy: 0.6902\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 8s 97ms/step - loss: 0.8105 - accuracy: 0.7134 - val_loss: 0.9270 - val_accuracy: 0.6922\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7942 - accuracy: 0.7172 - val_loss: 0.9357 - val_accuracy: 0.6892\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.7923 - accuracy: 0.7174 - val_loss: 0.9685 - val_accuracy: 0.6854\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.7828 - accuracy: 0.7218 - val_loss: 0.9041 - val_accuracy: 0.6974\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.7813 - accuracy: 0.7218 - val_loss: 0.9592 - val_accuracy: 0.6834\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7726 - accuracy: 0.7260 - val_loss: 0.9264 - val_accuracy: 0.6936\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 8s 97ms/step - loss: 0.7665 - accuracy: 0.7279 - val_loss: 0.9667 - val_accuracy: 0.6900\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7608 - accuracy: 0.7291 - val_loss: 1.0045 - val_accuracy: 0.6786\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7570 - accuracy: 0.7325 - val_loss: 0.9597 - val_accuracy: 0.6882\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7593 - accuracy: 0.7301 - val_loss: 0.9307 - val_accuracy: 0.6890\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7479 - accuracy: 0.7348 - val_loss: 0.9587 - val_accuracy: 0.6866\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 8s 97ms/step - loss: 0.7387 - accuracy: 0.7388 - val_loss: 0.9896 - val_accuracy: 0.6838\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7365 - accuracy: 0.7410 - val_loss: 1.0719 - val_accuracy: 0.6630\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7375 - accuracy: 0.7388 - val_loss: 0.9188 - val_accuracy: 0.7000\n",
      "Epoch 55/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7297 - accuracy: 0.7405 - val_loss: 0.9876 - val_accuracy: 0.6796\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7297 - accuracy: 0.7418 - val_loss: 1.0105 - val_accuracy: 0.6800\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7173 - accuracy: 0.7451 - val_loss: 0.9499 - val_accuracy: 0.6942\n",
      "Epoch 58/100\n",
      "88/88 [==============================] - 8s 95ms/step - loss: 0.7164 - accuracy: 0.7456 - val_loss: 0.9237 - val_accuracy: 0.6980\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7025 - accuracy: 0.7505 - val_loss: 0.9558 - val_accuracy: 0.6886\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.7037 - accuracy: 0.7475 - val_loss: 0.8999 - val_accuracy: 0.7088\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.6973 - accuracy: 0.7533 - val_loss: 0.9627 - val_accuracy: 0.6912\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6968 - accuracy: 0.7517 - val_loss: 0.9180 - val_accuracy: 0.7044\n",
      "Epoch 63/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.6907 - accuracy: 0.7535 - val_loss: 0.8945 - val_accuracy: 0.7078\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6835 - accuracy: 0.7578 - val_loss: 0.9416 - val_accuracy: 0.6952\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.6805 - accuracy: 0.7589 - val_loss: 0.9545 - val_accuracy: 0.6926\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.6775 - accuracy: 0.7591 - val_loss: 0.9385 - val_accuracy: 0.7014\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6703 - accuracy: 0.7602 - val_loss: 0.8792 - val_accuracy: 0.7186\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.6731 - accuracy: 0.7609 - val_loss: 0.8876 - val_accuracy: 0.7058\n",
      "Epoch 69/100\n",
      "88/88 [==============================] - 9s 101ms/step - loss: 0.6618 - accuracy: 0.7644 - val_loss: 0.9369 - val_accuracy: 0.7048\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - 8s 97ms/step - loss: 0.6686 - accuracy: 0.7626 - val_loss: 0.9408 - val_accuracy: 0.6994\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - 8s 97ms/step - loss: 0.6618 - accuracy: 0.7620 - val_loss: 0.9309 - val_accuracy: 0.7028\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.6573 - accuracy: 0.7666 - val_loss: 0.8984 - val_accuracy: 0.7080\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6454 - accuracy: 0.7701 - val_loss: 0.9729 - val_accuracy: 0.6942\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6521 - accuracy: 0.7678 - val_loss: 0.8955 - val_accuracy: 0.7130\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.6481 - accuracy: 0.7688 - val_loss: 0.9231 - val_accuracy: 0.7062\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6420 - accuracy: 0.7711 - val_loss: 0.9391 - val_accuracy: 0.7054\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6401 - accuracy: 0.7729 - val_loss: 0.9565 - val_accuracy: 0.7048\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6291 - accuracy: 0.7764 - val_loss: 0.8988 - val_accuracy: 0.7086\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6297 - accuracy: 0.7771 - val_loss: 0.8812 - val_accuracy: 0.7148\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6221 - accuracy: 0.7779 - val_loss: 1.0150 - val_accuracy: 0.6890\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6170 - accuracy: 0.7801 - val_loss: 0.9604 - val_accuracy: 0.7078\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.6165 - accuracy: 0.7792 - val_loss: 0.9189 - val_accuracy: 0.7140\n",
      "Epoch 83/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.6201 - accuracy: 0.7787 - val_loss: 0.8867 - val_accuracy: 0.7140\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.6160 - accuracy: 0.7810 - val_loss: 0.9797 - val_accuracy: 0.6974\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.6066 - accuracy: 0.7844 - val_loss: 0.9436 - val_accuracy: 0.7080\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 0.5982 - accuracy: 0.7848 - val_loss: 0.9686 - val_accuracy: 0.7028\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.6041 - accuracy: 0.7844 - val_loss: 0.9207 - val_accuracy: 0.7094\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.5951 - accuracy: 0.7868 - val_loss: 0.9562 - val_accuracy: 0.7028\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.5881 - accuracy: 0.7890 - val_loss: 0.9495 - val_accuracy: 0.7100\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.5927 - accuracy: 0.7876 - val_loss: 0.9022 - val_accuracy: 0.7186\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.5889 - accuracy: 0.7896 - val_loss: 0.9074 - val_accuracy: 0.7164\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.5832 - accuracy: 0.7915 - val_loss: 0.9119 - val_accuracy: 0.7170\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.5834 - accuracy: 0.7909 - val_loss: 0.8773 - val_accuracy: 0.7252\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.5815 - accuracy: 0.7906 - val_loss: 0.9164 - val_accuracy: 0.7172\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.5758 - accuracy: 0.7954 - val_loss: 0.8923 - val_accuracy: 0.7202\n",
      "Epoch 96/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.5676 - accuracy: 0.7977 - val_loss: 0.9114 - val_accuracy: 0.7142\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.5651 - accuracy: 0.7966 - val_loss: 0.9496 - val_accuracy: 0.7102\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - 8s 95ms/step - loss: 0.5655 - accuracy: 0.7957 - val_loss: 0.9058 - val_accuracy: 0.7198\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 0.5620 - accuracy: 0.8000 - val_loss: 0.9179 - val_accuracy: 0.7124\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.5646 - accuracy: 0.7978 - val_loss: 0.8671 - val_accuracy: 0.7266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f22d54305c0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixer_model.fit(x_train, y_train, validation_split=0.1, epochs=100, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0ffeed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 1.0963 - accuracy: 0.6991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0963000059127808, 0.6991000175476074]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c89c9",
   "metadata": {},
   "source": [
    "### Simple-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b5bede1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    layers_list=[128, 128, 128],\n",
    "    activation='relu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a9aeaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = models.simple_mlp(input_shape=(32, 32, 3), **parameters)\n",
    "mlp_model.compile(Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "00bd0f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 35.3909 - accuracy: 0.1539 - val_loss: 5.6088 - val_accuracy: 0.1762\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 3.8286 - accuracy: 0.2110 - val_loss: 2.8663 - val_accuracy: 0.2340\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 2.7686 - accuracy: 0.2323 - val_loss: 3.0729 - val_accuracy: 0.2226\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 2.4826 - accuracy: 0.2509 - val_loss: 2.2011 - val_accuracy: 0.2676\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 2.0473 - accuracy: 0.2889 - val_loss: 2.0857 - val_accuracy: 0.2930\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.9978 - accuracy: 0.2979 - val_loss: 2.0893 - val_accuracy: 0.2878\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.9604 - accuracy: 0.3070 - val_loss: 1.9956 - val_accuracy: 0.3074\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.9119 - accuracy: 0.3197 - val_loss: 1.9992 - val_accuracy: 0.3120\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.8995 - accuracy: 0.3272 - val_loss: 2.0455 - val_accuracy: 0.2912\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.8745 - accuracy: 0.3338 - val_loss: 1.8652 - val_accuracy: 0.3466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1cec0e14e0>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.fit(x_train, y_train, validation_split=0.1, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175db075",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "44353737",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_190\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization_162 (Normaliza (None, 32, 32, 3)         7         \n",
      "_________________________________________________________________\n",
      "random_flip_161 (RandomFlip) (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "random_rotation_161 (RandomR (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_2516 (Dense)           (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "activation_199 (Activation)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2517 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_200 (Activation)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2518 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_201 (Activation)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2519 (Dense)           (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 427,665\n",
      "Trainable params: 427,658\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fd8d8f",
   "metadata": {},
   "source": [
    "### CNN-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c286107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    layers_list=[128, 128, 128],\n",
    "    activation='relu',\n",
    ")\n",
    "conv_params=dict(\n",
    "    filters=128, \n",
    "    kernel_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d6957475",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mlp_model = models.cnn_mlp(input_shape=(32, 32, 3), conv_params=conv_params, **parameters)\n",
    "cnn_mlp_model.compile(Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "01d19b75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 [==============================] - 2s 17ms/step - loss: 104.9430 - accuracy: 0.1766 - val_loss: 5.2729 - val_accuracy: 0.2742\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 15ms/step - loss: 3.4084 - accuracy: 0.2780 - val_loss: 2.4697 - val_accuracy: 0.3170\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 15ms/step - loss: 2.5665 - accuracy: 0.3033 - val_loss: 2.3948 - val_accuracy: 0.3114\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 15ms/step - loss: 2.1525 - accuracy: 0.3292 - val_loss: 2.1010 - val_accuracy: 0.3500\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 15ms/step - loss: 1.9563 - accuracy: 0.3539 - val_loss: 2.0603 - val_accuracy: 0.3534\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 15ms/step - loss: 1.9746 - accuracy: 0.3552 - val_loss: 1.9942 - val_accuracy: 0.3718\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 15ms/step - loss: 1.9006 - accuracy: 0.3679 - val_loss: 2.0281 - val_accuracy: 0.3672\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 15ms/step - loss: 1.8738 - accuracy: 0.3766 - val_loss: 1.9262 - val_accuracy: 0.3706\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 15ms/step - loss: 1.8639 - accuracy: 0.3774 - val_loss: 1.9311 - val_accuracy: 0.3704\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 15ms/step - loss: 1.8485 - accuracy: 0.3820 - val_loss: 2.0347 - val_accuracy: 0.3660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1cec266550>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_mlp_model.fit(x_train, y_train, validation_split=0.1, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6c125c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 2.3027 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3027007579803467, 0.10000000149011612]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_mlp_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7d7b72f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_191\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization_163 (Normaliza (None, 32, 32, 3)         7         \n",
      "_________________________________________________________________\n",
      "random_flip_162 (RandomFlip) (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "random_rotation_162 (RandomR (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_176 (Conv2D)          (None, 29, 29, 128)       6272      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 107648)            0         \n",
      "_________________________________________________________________\n",
      "dense_2520 (Dense)           (None, 128)               13779072  \n",
      "_________________________________________________________________\n",
      "activation_202 (Activation)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2521 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_203 (Activation)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2522 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_204 (Activation)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2523 (Dense)           (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 13,819,665\n",
      "Trainable params: 13,819,658\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_mlp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ff123",
   "metadata": {},
   "source": [
    "## ハイパラ探索\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d987826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = dict(\n",
    "    epochs=100,\n",
    "    batch_size=512,\n",
    "    learning_rate=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882bf00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 100, 'batch_size': 512, 'learning_rate': 0.001}\n",
      "948 {'num_blocks': 24, 'patch_size': 2, 'hidden_dim': 16, 'tokens_mlp_dim': 16, 'channels_mlp_dim': 16, 'mlp_block_params': {'activation': 'gelu', 'dropout_rate': 0, 'batch_norm': True, 'dense_params': {'kernel_initializer': 'he_normal'}}}\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 1.1629 - accuracy: 0.6062\n",
      "949 {'num_blocks': 24, 'patch_size': 2, 'hidden_dim': 16, 'tokens_mlp_dim': 16, 'channels_mlp_dim': 16, 'mlp_block_params': {'activation': 'gelu', 'dropout_rate': 0, 'batch_norm': False, 'dense_params': {'kernel_initializer': 'he_normal'}}}\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 1.1710 - accuracy: 0.5890\n",
      "950 {'num_blocks': 24, 'patch_size': 2, 'hidden_dim': 16, 'tokens_mlp_dim': 16, 'channels_mlp_dim': 16, 'mlp_block_params': {'activation': 'gelu', 'dropout_rate': 0.5, 'batch_norm': True, 'dense_params': {'kernel_initializer': 'he_normal'}}}\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.9972 - accuracy: 0.6505\n",
      "951 {'num_blocks': 24, 'patch_size': 2, 'hidden_dim': 16, 'tokens_mlp_dim': 16, 'channels_mlp_dim': 16, 'mlp_block_params': {'activation': 'gelu', 'dropout_rate': 0.5, 'batch_norm': False, 'dense_params': {'kernel_initializer': 'he_normal'}}}\n"
     ]
    }
   ],
   "source": [
    "utils.mixer_parameter_search(\n",
    "    x_train, y_train, x_test, y_test, train_params=train_params, path='./results/epoch200/', start_i=948)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
